{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee529a3-f5c9-4a62-b27a-0aee2da8c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cbab3c3-0ab1-4f1e-a210-d9f6361c5fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.0 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "784c6c9c-689c-48fd-bd16-de2d7f133179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 476 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /home/cs242/.local/lib/python3.8/site-packages (from scikit-learn) (1.24.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.7 in /home/cs242/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=6.2.0 in /home/cs242/.local/lib/python3.8/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/cs242/.local/lib/python3.8/site-packages (from matplotlib) (23.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Installing collected packages: scipy, threadpoolctl, joblib, scikit-learn, fonttools, cycler, contourpy, kiwisolver, pyparsing, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 joblib-1.2.0 kiwisolver-1.4.4 matplotlib-3.6.3 pyparsing-3.0.9 scikit-learn-1.2.1 scipy-1.10.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396439ee-f9e8-4f9a-a1ec-8213ce4cee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /home/cs242/.local/lib/python3.8/site-packages (1.13.1+cpu)\n",
      "Requirement already satisfied: torchvision in /home/cs242/.local/lib/python3.8/site-packages (0.14.1+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/cs242/.local/lib/python3.8/site-packages (0.13.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/cs242/.local/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/cs242/.local/lib/python3.8/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/cs242/.local/lib/python3.8/site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /home/cs242/.local/lib/python3.8/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cs242/.local/lib/python3.8/site-packages (from requests->torchvision) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d905e76-4255-47c9-8568-51796e4a32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs242/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265025ae-8bfd-46f9-be15-5f50d1a6b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-distilroberta-v1') # you can change the model here\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ffa880-d335-4db0-834c-27c3f7d912d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abd30a4-74ba-4382-9527-bbddb431605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary to store tokenized sentences\n",
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    # encode each sentence and append to dictionary\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=512,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d368b0-d17c-444c-8a51-09a1bdc1ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat list of tensors into single tensor\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad79398-f976-414c-bdb7-de73d438bac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792515c2-d7b2-4fb1-9f8a-9916c39b77e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54247cef-7126-4ad9-977f-3c10ef63c797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1716, -0.5348,  0.1297,  ..., -0.2978, -0.8623,  0.2598],\n",
       "         [-0.8746,  0.4587, -0.1806,  ..., -0.4621, -0.9410,  0.3315],\n",
       "         [-0.7475,  0.2020, -0.1778,  ..., -0.2076, -0.7047,  0.1703],\n",
       "         ...,\n",
       "         [ 0.2735, -0.1972,  0.0317,  ..., -0.1275, -0.5828,  0.0128],\n",
       "         [ 0.2735, -0.1972,  0.0317,  ..., -0.1275, -0.5828,  0.0128],\n",
       "         [ 0.2735, -0.1972,  0.0317,  ..., -0.1275, -0.5828,  0.0128]],\n",
       "\n",
       "        [[ 0.3531, -1.0245,  0.1890,  ..., -1.0193,  0.1151,  0.1824],\n",
       "         [ 0.3335, -0.9922, -0.2278,  ..., -1.1686,  0.0174,  0.3293],\n",
       "         [ 0.9329, -0.3477,  0.6729,  ..., -1.2724,  0.1017,  0.6909],\n",
       "         ...,\n",
       "         [ 0.3406, -0.8891,  0.1748,  ..., -1.0470,  0.0745,  0.1729],\n",
       "         [ 0.3406, -0.8891,  0.1748,  ..., -1.0470,  0.0745,  0.1729],\n",
       "         [ 0.3406, -0.8891,  0.1748,  ..., -1.0470,  0.0745,  0.1729]],\n",
       "\n",
       "        [[-0.0592, -0.3647,  0.0537,  ..., -0.6969, -1.0904,  0.3171],\n",
       "         [-0.2030, -0.5321,  0.1347,  ..., -0.7476, -0.9570,  0.6857],\n",
       "         [-0.0995, -0.3777,  0.0382,  ..., -0.4864, -1.5908,  0.6873],\n",
       "         ...,\n",
       "         [-0.0943,  0.2369,  0.0859,  ..., -0.3808, -0.6180, -0.1497],\n",
       "         [-0.0943,  0.2369,  0.0859,  ..., -0.3808, -0.6180, -0.1497],\n",
       "         [-0.0943,  0.2369,  0.0859,  ..., -0.3808, -0.6180, -0.1497]],\n",
       "\n",
       "        [[-0.4414, -0.9817, -0.0113,  ..., -0.0349, -1.0438,  0.3843],\n",
       "         [-0.2232, -1.5730, -0.1715,  ..., -0.3142, -0.7643,  0.5921],\n",
       "         [ 0.0271, -0.7704,  0.3693,  ..., -0.1420, -1.0298,  0.3961],\n",
       "         ...,\n",
       "         [ 0.0859, -0.5215, -0.2689,  ...,  0.1420, -0.4515,  0.0972],\n",
       "         [ 0.0859, -0.5215, -0.2689,  ...,  0.1420, -0.4515,  0.0972],\n",
       "         [ 0.0859, -0.5215, -0.2689,  ...,  0.1420, -0.4515,  0.0972]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43705851-8ced-4c91-ad61-398ee603800d",
   "metadata": {},
   "source": [
    "After we have produced our dense vectors embeddings, we need to perform a mean pooling operation to create a single vector encoding (the sentence embedding). To do this mean pooling operation, we will need to multiply each value in our embeddings tensor by its respective attention_mask value — so that we ignore non-real tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e62c4382-fc9e-47b7-ace9-90876fc565f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize our attention_mask tensor:\n",
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b491e3d8-4d22-4e08-a2bf-8d00e3f472d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c94166-8bb7-44b3-8f14-39b9f832b131",
   "metadata": {},
   "source": [
    "Each vector above represents a single token attention mask - each token now has a vector of size 768 representing it's attention_mask status. Then we multiply the two tensors to apply the attention mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f214908-d7bf-48aa-a434-800858a5d46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4c604-715f-420f-9fdb-2ac9459a2023",
   "metadata": {},
   "source": [
    "\"Mean Pooling\" starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6802dde8-032f-4525-bd7b-6d6d1bbc2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we sum the remained of the embeddings along axis 1, because we want to reduce the 512 tokens to 1 dimension\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9057ad-35f2-48ea-8f65-ab825161377e",
   "metadata": {},
   "source": [
    "we want to count only those values that we want to give attention\n",
    "then divide by the sum to get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2875ec78-3d6a-4334-ac3a-de18ab6bb23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clamp returns the same tensor with a range given, clamp is used to replace the zeros to a very minimal value\n",
    "# to avoid divide by zero error\n",
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f27de-eee2-4ced-95dd-8d1c84d73bf6",
   "metadata": {},
   "source": [
    "Finally, we calculate the mean as the sum of the embedding activations summed divided by the number of values that should be given attention in each position `summed_mask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68564e3-c7e9-4008-84a6-e07eeeb451f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88430bd-b04a-41d9-a8c6-040389ac4d00",
   "metadata": {},
   "source": [
    "`mean_pooled` is the final \"dense representation\" of the sentences, note that mean_pooled contains all representations for all sentences together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626ff959-9c31-4568-aa62-53a971153065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2456, -0.3451,  0.1488,  ..., -0.2959, -0.8097,  0.2824],\n",
       "        [ 0.2976, -0.9414,  0.0986,  ..., -1.0383,  0.0247,  0.2000],\n",
       "        [-0.1320, -0.3896,  0.1188,  ..., -0.6403, -0.8874,  0.2990],\n",
       "        [-0.3522, -0.9329, -0.0272,  ...,  0.1638, -0.9243,  0.3892]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8d3e2-cb93-4966-85c8-52c0e3443a96",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e292d6-21f2-4250-881a-4bb9652ce67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_embedding(query):\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "    new_tokens = tokenizer.encode_plus(query, max_length=512,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    masked_embeddings = embeddings * mask\n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    mean_pooled = summed / summed_mask\n",
    "    \n",
    "    return mean_pooled[0] # assuming query is a single sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1eb20a7-b6aa-419a-9126-adaffa54a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb96482-d2c3-4d3b-8732-767683bf8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Nemo is a fish\"\n",
    "query_embedding = convert_to_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0f95da6-71d0-47dd-886a-b9ed601e5c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41a5033c-e6cf-46a8-9653-0d29b0562795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1189, 0.2486, 0.1139, 0.1814])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity()\n",
    "sim = cos(query_embedding, mean_pooled)\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850408bb-8d7c-4f96-9388-d119407938f1",
   "metadata": {},
   "source": [
    "# FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb7c08e3-270f-443c-81b7-85c67ee2dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import faiss                   # make faiss available\n",
    "index = faiss.IndexFlatIP(768)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(mean_pooled)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3be0a8c4-61b4-4801-92d7-63cbf6657675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d793c9cb-27eb-4505-9e1c-41d85592bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed57aaed-351a-48d4-bef5-62a39a61834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(query_embedding[None, :], 1) # None dimension is added because we only have one query against 4 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6da8a1b8-c0ab-4568-b100-1150addcf9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.04268]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6d5efcf-c042-4d43-af51-027d9c158fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a94e449-cbd6-4bc8-898c-8b07da14dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index,\"sample_code.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28123327-d986-493d-a413-b6ed621f4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_loaded = faiss.read_index(\"sample_code.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2fe74a9-69c6-47db-a271-1da7d0989615",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index_loaded.search(query_embedding[None, :], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32287a19-0e0a-4e72-8042-8f1bf431c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.04268 , 26.346306, 17.326878, 14.138208]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b7b7b2f-ab4a-4f26-84a6-417c51951300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 0, 2]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d667e30-e0be-44a1-b970-260d23f47bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
